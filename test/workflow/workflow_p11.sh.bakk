#!/bin/bash

# 并行对接脚本
# 用法: ./run_docking.sh [并发任务数] [清理模式]

# 设置基础路径
REGISTRY_DIR="./registry"
AMBIG_RESTRAINTS_DIR="$REGISTRY_DIR/ambig_restraints"
LOG_DIR="$REGISTRY_DIR/docking_logs"
CFG_PATTERN="docking-antibody-antigen_updated.cfg"

# 设置默认并发任务数
DEFAULT_JOBS=$(( $(nproc) / 4 ))  # 降低并发度为CPU核心数的1/4
MAX_JOBS=${1:-$DEFAULT_JOBS}
CLEAN_MODE=${2:-safe}  # 默认安全模式: safe | force

# 创建日志目录
mkdir -p "$LOG_DIR"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
JOB_LOG="$LOG_DIR/docking_joblog_$TIMESTAMP.txt"
SUMMARY_LOG="$LOG_DIR/docking_summary_$TIMESTAMP.csv"

# 查找所有配置文件
echo "正在搜索配置文件..."
cfg_files=($(find "$AMBIG_RESTRAINTS_DIR" -type f -name "$CFG_PATTERN"))
total_jobs=${#cfg_files[@]}

if [[ $total_jobs -eq 0 ]]; then
    echo "错误: 未找到任何配置文件 ($CFG_PATTERN)" >&2
    exit 1
fi

echo "找到 $total_jobs 个对接任务"
echo "最大并发任务数: $MAX_JOBS"
echo "清理模式: $CLEAN_MODE"

# 收集所有运行目录
echo "收集运行目录信息..."
declare -A run_dirs
for cfg_file in "${cfg_files[@]}"; do
    run_dir=$(awk -F'=' '/^run_dir/ {gsub(/[[:space:]]+/, "", $2); print $2}' "$cfg_file")
    run_dirs["$run_dir"]="$cfg_file"
done

# 清理残留的运行目录
echo "清理残留的运行目录..."
cleaned_count=0
for run_dir in "${!run_dirs[@]}"; do
    if [ -d "$run_dir" ]; then
        if [ "$CLEAN_MODE" == "force" ]; then
            # 强制模式: 删除整个目录
            echo "⚠️ 强制删除目录: $run_dir"
            rm -rf "$run_dir"
            ((cleaned_count++))
        else
            # 安全模式: 只删除特定文件
            echo "⚠️ 安全清理目录: $run_dir"
            # 删除HADDOCK3生成的临时文件和锁文件
            find "$run_dir" -maxdepth 1 -type f \( -name "*.inp" -o -name "*.out" -o -name "*.err" -o -name "*.log" -o -name ".haddock_lock" \) -delete
            # 删除空目录
            find "$run_dir" -type d -empty -delete
            ((cleaned_count++))
        fi
    fi
done
echo "清理完成: $cleaned_count 个目录"

# 创建父目录
echo "创建父目录..."
parent_dirs=()
for run_dir in "${!run_dirs[@]}"; do
    parent_dir=$(dirname "$run_dir")
    parent_dirs+=("$parent_dir")
done

# 去重并创建父目录
printf "%s\n" "${parent_dirs[@]}" | sort -u | while read dir; do
    mkdir -p "$dir"
done

# 写入CSV表头
echo "cfg_path,status,time,output_dir" > "$SUMMARY_LOG"

# 定义带锁机制的对接函数
run_docking() {
    local cfg_file="$1"
    local log_id=$(basename $(dirname $(dirname "$cfg_file")))
    local log_file="$LOG_DIR/${log_id}_${TIMESTAMP}.log"
    
    # 提取运行目录
    local run_dir=$(awk -F'=' '/^run_dir/ {gsub(/[[:space:]]+/, "", $2); print $2}' "$cfg_file")
    local lock_file="$run_dir/.haddock_lock"
    
    # 确保运行目录不存在
    if [ -d "$run_dir" ]; then
        if [ -z "$(ls -A "$run_dir")" ]; then
            # 如果是空目录，删除它
            rmdir "$run_dir"
        else
            # 如果非空目录仍然存在，记录错误
            echo "❌ 错误: 运行目录非空且无法清理: $run_dir" | tee -a "$log_file"
            return 1
        fi
    fi
    
    # 目录锁检查
    if [ -f "$lock_file" ]; then
        echo "⚠️ 跳过: $cfg_file (已在运行)" | tee -a "$log_file"
        return 1
    fi
    touch "$lock_file"
    
    # 资源检查 - 避免系统过载
    local load=$(awk '{print $1}' /proc/loadavg | cut -d. -f1)
    local mem_avail=$(free -m | awk '/Mem:/ {print $7}')
    if [ $load -gt $(nproc) ] || [ $mem_avail -lt 2048 ]; then
        echo "⚠️ 资源紧张: 负载 $load | 内存 ${mem_avail}MB - 随机延迟" | tee -a "$log_file"
        sleep $(( RANDOM % 30 + 10 )) # 随机延迟10-40秒
    fi
    
    echo "启动对接: $cfg_file" | tee -a "$log_file"
    echo "运行目录: $run_dir" | tee -a "$log_file"
    
    local start_time=$(date +%s)
    
    # 运行对接（带超时防止卡住）
    timeout 12h haddock3 "$cfg_file" > "$log_file" 2>&1
    local status=$?
    
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    
    # 释放锁
    rm -f "$lock_file"
    
    if [[ $status -eq 0 ]]; then
        echo "✅ 成功: $cfg_file (用时: ${duration}秒)" | tee -a "$log_file"
        echo "$cfg_file,success,$duration,$run_dir" >> "$SUMMARY_LOG"
    else
        echo "❌ 失败[代码:$status]: $cfg_file (用时: ${duration}秒)" | tee -a "$log_file"
        echo "$cfg_file,failed-$status,$duration,$run_dir" >> "$SUMMARY_LOG"
        
        # 提取错误信息
        local error_msg=$(grep -i -m1 -e "error" -e "fail" -e "exception" "$log_file" | head -1)
        echo "   错误信息: ${error_msg:0:120}..." | tee -a "$log_file"
    fi
    
    return $status
}

# 导出函数用于parallel
export -f run_docking
export TIMESTAMP
export LOG_DIR
export SUMMARY_LOG
export CLEAN_MODE

echo "开始并行对接..."

# 禁用GNU Parallel的引用提示
export PARALLEL_HOME="$LOG_DIR"
mkdir -p "$PARALLEL_HOME"
echo '--will-cite' > "$PARALLEL_HOME/config"

# 使用parallel并行运行
parallel --link --progress --bar --eta -j "$MAX_JOBS" \
    --joblog "$JOB_LOG" \
    --retries 1 \
    --resume-failed \
    --halt soon,fail=10% \
    --delay 0.1 \
    run_docking ::: "${cfg_files[@]}" </dev/null

# 生成摘要报告
success_count=$(grep -c "success" "$SUMMARY_LOG")
failed_count=$((total_jobs - success_count))

echo ""
echo "===== 对接摘要 ====="
echo "总任务数: $total_jobs"
echo "成功任务: $success_count"
echo "失败任务: $failed_count"
echo "总用时: $(awk -F',' 'NR>1 {sum+=$3} END {print sum "秒 (" int(sum/60) "分)"}' "$SUMMARY_LOG")"
echo ""
echo "详细日志: $JOB_LOG"
echo "摘要报告: $SUMMARY_LOG"

if [[ $failed_count -gt 0 ]]; then
    echo ""
    echo "失败任务列表:"
    grep "failed" "$SUMMARY_LOG" | cut -d',' -f1
    echo ""
    echo "请检查失败任务的日志文件获取详细信息"
    
    # 如果有失败任务，建议使用强制清理模式
    if [ "$CLEAN_MODE" != "force" ]; then
        echo ""
        echo "提示: 部分失败可能是由于残留文件导致，可以尝试使用强制清理模式重新运行:"
        echo "      $0 $MAX_JOBS force"
    fi
fi

exit 0
